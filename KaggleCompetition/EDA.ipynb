{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING ONLY RAW DATA AND NO FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def test_model_out_of_the_box(model, model_name):\n",
    "    model_all_data = copy.deepcopy(model)\n",
    "\n",
    "    #Load in data\n",
    "    df = pd.read_csv('./data/raw/train_final.csv', index_col = 0)\n",
    "    df_test = pd.read_csv('./data/raw/test_final.csv', index_col=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop('Y', axis=1), df['Y'], test_size=0.2, random_state=42) # Create split for dev stuff\n",
    "    x = df.drop('Y', axis=1)\n",
    "    y = df['Y']\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        model_all_data.fit(x, y, verbose=False)  \n",
    "    except:\n",
    "        model.fit(X_train, y_train)\n",
    "        model_all_data.fit(x, y)  \n",
    "\n",
    "    print('Using only train data AUC ROC score:', metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])) \n",
    "\n",
    "    # Spit Out\n",
    "    df_test['Y'] = model_all_data.predict_proba(df_test)[:,1]\n",
    "    df_test['Y'].to_csv(f'./preds/{model_name}_out_of_the_box.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Out of the box - 0.87046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only train data AUC ROC score: 0.874332337973672\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Get an idea of how out of the box submissions will look\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "test_model_out_of_the_box(model_xgb, model_name='xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Out of the box - 0.89352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only train data AUC ROC score: 0.9237498422845607\n"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "model_cb = cb.CatBoostClassifier()\n",
    "test_model_out_of_the_box(model_cb, model_name='cb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm Out of the box - 0.86941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only train data AUC ROC score: 0.8872650039954578\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "test_model_out_of_the_box(lgbm.LGBMClassifier(), model_name='lgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Out of the Box - 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only train data AUC ROC score: 0.808386255625184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "test_model_out_of_the_box(RandomForestClassifier(), model_name='rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Re-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_categorical(df):\n",
    "    cat = []\n",
    "    const = []\n",
    "    contin = []\n",
    "    for c in df.columns:\n",
    "        x = len(df[c].value_counts())\n",
    "        if x == 1:\n",
    "            const.append(c)\n",
    "            #print(f'Column {c} is likely CONSTANT')\n",
    "        elif x < 10:\n",
    "            #print(f'Column {c} is likely categorical w/ {x} categories')\n",
    "            cat.append((c, x))\n",
    "        else:\n",
    "            #print(f'Columns {c} is likely continuous... Has {x} unique values')\n",
    "            contin.append((c, x))\n",
    "\n",
    "    return np.array(cat), const, contin\n",
    "\n",
    "def convert_categorical(df, info, onehot=False):\n",
    "    cache = {}\n",
    "    for c, n in info:\n",
    "        col_cache = {}\n",
    "        u = np.sort(df[c].unique())\n",
    "        arr = np.arange(len(u))\n",
    "        f = lambda x: arr[np.where(u==x)[0][0]] if len(np.where(u==x)[0]) > 0 else x\n",
    "        df[c] = df[c].map(f)\n",
    "        col_cache['f'] = f\n",
    "        col_cache['arr'] = arr\n",
    "        col_cache['unique'] = u\n",
    "\n",
    "        if onehot:\n",
    "            pass #TODO convert the now categorized column into onehot representations\n",
    "            #Must store the one hotters for consistency\n",
    "\n",
    "        cache[c] = col_cache\n",
    "\n",
    "    return df, cache\n",
    "\n",
    "def train_preprocess(df, onehot=False):\n",
    "    categ, const, contin = find_categorical(df)\n",
    "    df = df.drop(const[1:], axis=1) # Drop all constants except 1\n",
    "    df, categ_cache = convert_categorical(df, categ, onehot)\n",
    "    cache = {\n",
    "        'categ': categ_cache,\n",
    "        'const': const\n",
    "    }\n",
    "    return df, cache\n",
    "\n",
    "def test_preprocess(df, cache):\n",
    "\n",
    "    # Drop all columns except 1 from cache['const']\n",
    "    df = df.drop(cache['const'][1:], axis=1)\n",
    "    # Convert all categorical from cache['categ']\n",
    "    for c in cache['categ']:\n",
    "        col_cache = cache['categ'][c]\n",
    "        arr = col_cache['arr']\n",
    "        u = col_cache['unique']\n",
    "        df[c] = df[c].map(col_cache['f'])\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train_df = pd.read_csv('./data/raw/train_final.csv', index_col=0)\n",
    "test_df = pd.read_csv('./data/raw/test_final.csv', index_col=0)\n",
    "\n",
    "x = train_df.drop('Y', axis=1)\n",
    "y = train_df['Y']\n",
    "pp_train, cache = train_preprocess(x.copy())\n",
    "pp_test = test_preprocess(test_df.copy(), cache)\n",
    "x_train, x_test, y_train, y_test = train_test_split(pp_train, y, test_size=0.2, random_state=42) # Create split for dev stuff\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST\n",
    "- Hyperparameter Tuned\n",
    "- Feature Engineered\n",
    "- Hyperparameter Tuned + Feature Engineered"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ============== Feature Engineering ==================== <- Failure\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier().fit(x_train, y_train)\n",
    "print('Feature Engineered XGBoost AUC score: ', metrics.roc_auc_score(y_test, model.predict_proba(x_test)[:,1]))\n",
    "\n",
    "model = xgb.XGBClassifier().fit(pp_train, y)\n",
    "pp_test['Y'] = model.predict_proba(pp_test)[:,1]\n",
    "pp_test['Y'].to_csv('./preds/xgb_feature_engineered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/raw/train_final.csv', index_col = 0)\n",
    "x = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "test_df = pd.read_csv('./data/raw/test_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'eta': 0.04,\n",
    "    'gamma':0,\n",
    "    'max_depth':5,\n",
    "    'min_child_weight':1\n",
    "}\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.1)\n",
      "\tm0:  0.8632852623361683\n",
      "\tm1:  0.8800033849538801\n",
      "\tm2:  0.8707487391697918\n",
      "\tm3:  0.8925540365399891\n",
      "\tm4:  0.8767822854107938\n",
      "\tm5:  0.8976309226932668\n",
      "\tm6:  0.8838322271885863\n",
      "\tm7:  0.8744525547445257\n",
      "\tm8:  0.889364303178484\n",
      "\tm9:  0.864389418366438\n",
      "Predicted AUC score: 0.8793043134581924\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.12916666666666668)\n",
      "\tm0:  0.8753610069399543\n",
      "\tm1:  0.8889569800220615\n",
      "\tm2:  0.8961748633879781\n",
      "\tm3:  0.9054517329319787\n",
      "\tm4:  0.8930630209550519\n",
      "\tm5:  0.8913847161776405\n",
      "\tm6:  0.8550884503819913\n",
      "\tm7:  0.887769693401186\n",
      "\tm8:  0.8897729555957403\n",
      "\tm9:  0.869851802698518\n",
      "Predicted AUC score: 0.88528752224921\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.15833333333333335)\n",
      "\tm0:  0.86468219729652\n",
      "\tm1:  0.8611159622773314\n",
      "\tm2:  0.8818010372465819\n",
      "\tm3:  0.8928845546074315\n",
      "\tm4:  0.8943801652892562\n",
      "\tm5:  0.8897912284801744\n",
      "\tm6:  0.8719604524806271\n",
      "\tm7:  0.8600917431192661\n",
      "\tm8:  0.850688836104513\n",
      "\tm9:  0.8722701976587987\n",
      "Predicted AUC score: 0.87396663745605\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.1875)\n",
      "\tm0:  0.8949632178452778\n",
      "\tm1:  0.8897884510240989\n",
      "\tm2:  0.8824231363189667\n",
      "\tm3:  0.8713888540490823\n",
      "\tm4:  0.8637693883523558\n",
      "\tm5:  0.8899777095512471\n",
      "\tm6:  0.8591534910323978\n",
      "\tm7:  0.8591655155602502\n",
      "\tm8:  0.8747055043906619\n",
      "\tm9:  0.8791639017916391\n",
      "Predicted AUC score: 0.8764499169915979\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.21666666666666667)\n",
      "\tm0:  0.8758350405273003\n",
      "\tm1:  0.8873921698739217\n",
      "\tm2:  0.8722210323409725\n",
      "\tm3:  0.8875353535353535\n",
      "\tm4:  0.8908029897278067\n",
      "\tm5:  0.847994414826098\n",
      "\tm6:  0.906931949763962\n",
      "\tm7:  0.8883827867430159\n",
      "\tm8:  0.8843630399125205\n",
      "\tm9:  0.8818973663667365\n",
      "Predicted AUC score: 0.8823356143617687\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.24583333333333335)\n",
      "\tm0:  0.8872332118688182\n",
      "\tm1:  0.8731800766283525\n",
      "\tm2:  0.8909883064698181\n",
      "\tm3:  0.8925488702716425\n",
      "\tm4:  0.8552398272334623\n",
      "\tm5:  0.8709658281917417\n",
      "\tm6:  0.8597267069118817\n",
      "\tm7:  0.8877926801545806\n",
      "\tm8:  0.8687016146870161\n",
      "\tm9:  0.8879417434140073\n",
      "Predicted AUC score: 0.8774318865831321\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.275)\n",
      "\tm0:  0.8927383049520454\n",
      "\tm1:  0.8772558230573497\n",
      "\tm2:  0.8614416159380188\n",
      "\tm3:  0.8771310447345194\n",
      "\tm4:  0.8588586595885866\n",
      "\tm5:  0.8475274725274725\n",
      "\tm6:  0.8759168704156479\n",
      "\tm7:  0.9050872711792252\n",
      "\tm8:  0.8950797393980575\n",
      "\tm9:  0.8999787143465304\n",
      "Predicted AUC score: 0.8791015516137455\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.3041666666666667)\n",
      "\tm0:  0.8641092636579573\n",
      "\tm1:  0.8730853854616231\n",
      "\tm2:  0.8785321907273127\n",
      "\tm3:  0.9135574598989233\n",
      "\tm4:  0.8529820839226779\n",
      "\tm5:  0.8853137910682668\n",
      "\tm6:  0.8965943339361061\n",
      "\tm7:  0.8906824500044839\n",
      "\tm8:  0.8982121088988216\n",
      "\tm9:  0.886987270155587\n",
      "Predicted AUC score: 0.8840056337731758\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.33333333333333337)\n",
      "\tm0:  0.9015780730897011\n",
      "\tm1:  0.8539276807980051\n",
      "\tm2:  0.8686037373384562\n",
      "\tm3:  0.8879453370590291\n",
      "\tm4:  0.8769954884608712\n",
      "\tm5:  0.8846053091163115\n",
      "\tm6:  0.8915473279776458\n",
      "\tm7:  0.8787992809063925\n",
      "\tm8:  0.8950170785613824\n",
      "\tm9:  0.8999064754609424\n",
      "Predicted AUC score: 0.8838925788768737\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.36250000000000004)\n",
      "\tm0:  0.8850475558504757\n",
      "\tm1:  0.8926546500803928\n",
      "\tm2:  0.8796581617979374\n",
      "\tm3:  0.8582663918913236\n",
      "\tm4:  0.8783574380165289\n",
      "\tm5:  0.9035806537810634\n",
      "\tm6:  0.8977697408077154\n",
      "\tm7:  0.8649955839676999\n",
      "\tm8:  0.9062820986893463\n",
      "\tm9:  0.8719771207469403\n",
      "Predicted AUC score: 0.8838589395629424\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.3916666666666667)\n",
      "\tm0:  0.8704874363867684\n",
      "\tm1:  0.8768696926591663\n",
      "\tm2:  0.8609882005899705\n",
      "\tm3:  0.8950516953361326\n",
      "\tm4:  0.8707182541268635\n",
      "\tm5:  0.8653895274584931\n",
      "\tm6:  0.8737739281759216\n",
      "\tm7:  0.8745341614906833\n",
      "\tm8:  0.878159565967111\n",
      "\tm9:  0.8658261446582614\n",
      "Predicted AUC score: 0.8731798606849372\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.4208333333333334)\n",
      "\tm0:  0.8884068693390728\n",
      "\tm1:  0.8610532708658685\n",
      "\tm2:  0.8749390590720729\n",
      "\tm3:  0.8546552949538023\n",
      "\tm4:  0.8619507504494336\n",
      "\tm5:  0.8419891299298556\n",
      "\tm6:  0.8852048153169809\n",
      "\tm7:  0.8540669856459331\n",
      "\tm8:  0.8723993363823873\n",
      "\tm9:  0.8940277901487487\n",
      "Predicted AUC score: 0.8688693302104156\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.45000000000000007)\n",
      "\tm0:  0.893726653482751\n",
      "\tm1:  0.8699114325180792\n",
      "\tm2:  0.8604038630377524\n",
      "\tm3:  0.8955061983471074\n",
      "\tm4:  0.8835152746043836\n",
      "\tm5:  0.8996719518862767\n",
      "\tm6:  0.9001652892561983\n",
      "\tm7:  0.8565183641786167\n",
      "\tm8:  0.9053473848555814\n",
      "\tm9:  0.86372257424889\n",
      "Predicted AUC score: 0.8828488986415636\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.47916666666666674)\n",
      "\tm0:  0.8844292139644464\n",
      "\tm1:  0.8670524591577223\n",
      "\tm2:  0.8903266433736898\n",
      "\tm3:  0.8816508484325567\n",
      "\tm4:  0.8758148631029986\n",
      "\tm5:  0.898708598504204\n",
      "\tm6:  0.8869492934330839\n",
      "\tm7:  0.8726145038167938\n",
      "\tm8:  0.8818162347397731\n",
      "\tm9:  0.8633707061068702\n",
      "Predicted AUC score: 0.8802733364632138\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.5083333333333334)\n",
      "\tm0:  0.8821199317461608\n",
      "\tm1:  0.8794281435724647\n",
      "\tm2:  0.8805988980947975\n",
      "\tm3:  0.8786642553728393\n",
      "\tm4:  0.8754125412541255\n",
      "\tm5:  0.8733990147783252\n",
      "\tm6:  0.885434858539993\n",
      "\tm7:  0.8893154606975534\n",
      "\tm8:  0.8909961685823754\n",
      "\tm9:  0.9042963477187705\n",
      "Predicted AUC score: 0.8839665620357404\n",
      "Best Previous Score: 0.8877878897972294\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.5375000000000001)\n",
      "\tm0:  0.8963431786216597\n",
      "\tm1:  0.8959706959706959\n",
      "\tm2:  0.8755165289256198\n",
      "\tm3:  0.891188749725335\n",
      "\tm4:  0.9153574397339983\n",
      "\tm5:  0.884729064039409\n",
      "\tm6:  0.8737590390979286\n",
      "\tm7:  0.9070109769945746\n",
      "\tm8:  0.8759338682899834\n",
      "\tm9:  0.8658536585365854\n",
      "Predicted AUC score: 0.8881663199935789\n",
      "Best Previous Score: 0.8877878897972294\n",
      "!!!!!!!!!!!!!!!Found new best parameters!!!!!!!!\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.5666666666666668)\n",
      "\tm0:  0.8961570247933884\n",
      "\tm1:  0.8763965201465203\n",
      "\tm2:  0.8869326891810285\n",
      "\tm3:  0.8933375904640272\n",
      "\tm4:  0.8790750915750916\n",
      "\tm5:  0.8895247933884297\n",
      "\tm6:  0.8882644628099173\n",
      "\tm7:  0.8378742214185252\n",
      "\tm8:  0.9165582162068366\n",
      "\tm9:  0.8812150181803325\n",
      "Predicted AUC score: 0.8845335628164097\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.5958333333333334)\n",
      "\tm0:  0.8778588807785888\n",
      "\tm1:  0.8920562977099236\n",
      "\tm2:  0.8591534117849907\n",
      "\tm3:  0.9081298213357848\n",
      "\tm4:  0.8814949668023131\n",
      "\tm5:  0.8673077791322408\n",
      "\tm6:  0.8883654058836541\n",
      "\tm7:  0.8760606060606062\n",
      "\tm8:  0.8771068347710683\n",
      "\tm9:  0.8742934330839567\n",
      "Predicted AUC score: 0.8801827437343126\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.625)\n",
      "\tm0:  0.8823648923201951\n",
      "\tm1:  0.8689093608103388\n",
      "\tm2:  0.8910216442504675\n",
      "\tm3:  0.8556105610561056\n",
      "\tm4:  0.8838944810829573\n",
      "\tm5:  0.8804701627486439\n",
      "\tm6:  0.882089461282197\n",
      "\tm7:  0.8833139359455149\n",
      "\tm8:  0.8930177768258728\n",
      "\tm9:  0.9120157513835675\n",
      "Predicted AUC score: 0.8832708027705861\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.6541666666666667)\n",
      "\tm0:  0.8764170869434027\n",
      "\tm1:  0.9113565202674113\n",
      "\tm2:  0.8851802698518026\n",
      "\tm3:  0.902919708029197\n",
      "\tm4:  0.8932457447288816\n",
      "\tm5:  0.8767347807577693\n",
      "\tm6:  0.8699038331301638\n",
      "\tm7:  0.875048493469546\n",
      "\tm8:  0.883886760323542\n",
      "\tm9:  0.8577536296428254\n",
      "Predicted AUC score: 0.8832446827144542\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.6833333333333333)\n",
      "\tm0:  0.8814735489398159\n",
      "\tm1:  0.888808519188266\n",
      "\tm2:  0.8701787994891443\n",
      "\tm3:  0.8717539378458921\n",
      "\tm4:  0.884348000803697\n",
      "\tm5:  0.8904159132007232\n",
      "\tm6:  0.8885674991267901\n",
      "\tm7:  0.8949528466643382\n",
      "\tm8:  0.9061264040499921\n",
      "\tm9:  0.8808298343040317\n",
      "Predicted AUC score: 0.885745530361269\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.7125)\n",
      "\tm0:  0.9091935281575317\n",
      "\tm1:  0.8925642427556042\n",
      "\tm2:  0.8339056776556776\n",
      "\tm3:  0.9028178435553326\n",
      "\tm4:  0.8767529307675292\n",
      "\tm5:  0.8854260959524118\n",
      "\tm6:  0.87578112640405\n",
      "\tm7:  0.8673465330788804\n",
      "\tm8:  0.8792252022137079\n",
      "\tm9:  0.8925930465334805\n",
      "Predicted AUC score: 0.8815606227074205\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.7416666666666667)\n",
      "\tm0:  0.892737076493189\n",
      "\tm1:  0.8736565964288737\n",
      "\tm2:  0.866019294237116\n",
      "\tm3:  0.9074815145851953\n",
      "\tm4:  0.844842450105608\n",
      "\tm5:  0.8869509840174207\n",
      "\tm6:  0.8718583396801218\n",
      "\tm7:  0.870609871855719\n",
      "\tm8:  0.8786705593636287\n",
      "\tm9:  0.8879006410256409\n",
      "Predicted AUC score: 0.8780727327792514\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.7708333333333334)\n",
      "\tm0:  0.8907100199071002\n",
      "\tm1:  0.8873282967032967\n",
      "\tm2:  0.8786207515021075\n",
      "\tm3:  0.8551059958867266\n",
      "\tm4:  0.8891987027369088\n",
      "\tm5:  0.8887203108627314\n",
      "\tm6:  0.87696613147036\n",
      "\tm7:  0.886979829534498\n",
      "\tm8:  0.8829829874409906\n",
      "\tm9:  0.8593731163351417\n",
      "Predicted AUC score: 0.8795986142379861\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.045) (Depth = 5) (Gamma = 0.8)\n",
      "\tm0:  0.8910807600950119\n",
      "\tm1:  0.8981762250054932\n",
      "\tm2:  0.9016475788627688\n",
      "\tm3:  0.9069876191324486\n",
      "\tm4:  0.8585072476423332\n",
      "\tm5:  0.8731302568765629\n",
      "\tm6:  0.8744544401888306\n",
      "\tm7:  0.8662195953625824\n",
      "\tm8:  0.8902066115702478\n",
      "\tm9:  0.8585643212508884\n",
      "Predicted AUC score: 0.8818974655987167\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.1)\n",
      "\tm0:  0.8901443816698055\n",
      "\tm1:  0.8782733588670171\n",
      "\tm2:  0.8969175689835837\n",
      "\tm3:  0.8701013096120583\n",
      "\tm4:  0.8465425993406211\n",
      "\tm5:  0.8819130134919609\n",
      "\tm6:  0.8704900021973193\n",
      "\tm7:  0.8934777004382572\n",
      "\tm8:  0.9063057127354468\n",
      "\tm9:  0.8813865971920682\n",
      "Predicted AUC score: 0.8815552244528139\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.12916666666666668)\n",
      "\tm0:  0.87006008293137\n",
      "\tm1:  0.8745734181885261\n",
      "\tm2:  0.8841854564603381\n",
      "\tm3:  0.9087384878989077\n",
      "\tm4:  0.8753543695303834\n",
      "\tm5:  0.8840128222493114\n",
      "\tm6:  0.898935946502923\n",
      "\tm7:  0.8953415872450343\n",
      "\tm8:  0.8802917039083449\n",
      "\tm9:  0.8837225274725274\n",
      "Predicted AUC score: 0.8855216402387664\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.15833333333333335)\n",
      "\tm0:  0.8868384233125873\n",
      "\tm1:  0.8733264462809918\n",
      "\tm2:  0.8944923689449237\n",
      "\tm3:  0.8692148760330578\n",
      "\tm4:  0.866425557564798\n",
      "\tm5:  0.8607617465590888\n",
      "\tm6:  0.9063702720637027\n",
      "\tm7:  0.9058471074380167\n",
      "\tm8:  0.8769898989898989\n",
      "\tm9:  0.8678116595475399\n",
      "Predicted AUC score: 0.8808078356734604\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.1875)\n",
      "\tm0:  0.8943089430894309\n",
      "\tm1:  0.897033934162647\n",
      "\tm2:  0.8844720496894409\n",
      "\tm3:  0.8715922338803694\n",
      "\tm4:  0.8776583313858378\n",
      "\tm5:  0.9112253926122541\n",
      "\tm6:  0.8480001634187195\n",
      "\tm7:  0.8935392117025599\n",
      "\tm8:  0.8658839722256461\n",
      "\tm9:  0.8998570374469655\n",
      "Predicted AUC score: 0.8843571269613871\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.21666666666666667)\n",
      "\tm0:  0.8784302211783127\n",
      "\tm1:  0.8827054396804013\n",
      "\tm2:  0.8772133178784124\n",
      "\tm3:  0.8913641364136412\n",
      "\tm4:  0.8799934080421885\n",
      "\tm5:  0.8999382930309692\n",
      "\tm6:  0.8738611757976876\n",
      "\tm7:  0.8694326449930605\n",
      "\tm8:  0.8821504356855838\n",
      "\tm9:  0.8673333333333333\n",
      "Predicted AUC score: 0.8802422406033589\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.24583333333333335)\n",
      "\tm0:  0.8730898533007335\n",
      "\tm1:  0.8777245636441039\n",
      "\tm2:  0.8719133900324582\n",
      "\tm3:  0.8825487663667944\n",
      "\tm4:  0.8848834789846025\n",
      "\tm5:  0.8716184791876599\n",
      "\tm6:  0.8581840300818403\n",
      "\tm7:  0.8851788022404137\n",
      "\tm8:  0.8903591287261172\n",
      "\tm9:  0.8834397616006812\n",
      "Predicted AUC score: 0.8778940254165404\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.275)\n",
      "\tm0:  0.8901616161616162\n",
      "\tm1:  0.8779150077191842\n",
      "\tm2:  0.8420762348327001\n",
      "\tm3:  0.857464125080317\n",
      "\tm4:  0.8713365943392283\n",
      "\tm5:  0.8852999340804218\n",
      "\tm6:  0.8876453236161722\n",
      "\tm7:  0.8852752273804907\n",
      "\tm8:  0.8451859504132232\n",
      "\tm9:  0.8711180124223603\n",
      "Predicted AUC score: 0.8713478026045713\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.3041666666666667)\n",
      "\tm0:  0.8964034558971267\n",
      "\tm1:  0.8796829676839482\n",
      "\tm2:  0.878777688099722\n",
      "\tm3:  0.8759477404155065\n",
      "\tm4:  0.8764789497888709\n",
      "\tm5:  0.8867114594998133\n",
      "\tm6:  0.8813979896538672\n",
      "\tm7:  0.8818181818181818\n",
      "\tm8:  0.8757833200151408\n",
      "\tm9:  0.8529093931837074\n",
      "Predicted AUC score: 0.8785911146055886\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.33333333333333337)\n",
      "\tm0:  0.8600021417862497\n",
      "\tm1:  0.8977036575228595\n",
      "\tm2:  0.8688246526367107\n",
      "\tm3:  0.883936603127008\n",
      "\tm4:  0.8571107570372185\n",
      "\tm5:  0.8944731404958679\n",
      "\tm6:  0.8586983471074381\n",
      "\tm7:  0.8934330839567747\n",
      "\tm8:  0.8494118642633494\n",
      "\tm9:  0.8832851239669421\n",
      "Predicted AUC score: 0.874687937190042\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.36250000000000004)\n",
      "\tm0:  0.8888526340768865\n",
      "\tm1:  0.8811669628501312\n",
      "\tm2:  0.8466947960618846\n",
      "\tm3:  0.8570592416070906\n",
      "\tm4:  0.8865298982188295\n",
      "\tm5:  0.8750957854406131\n",
      "\tm6:  0.8732706142778085\n",
      "\tm7:  0.894330655675653\n",
      "\tm8:  0.9001004621257785\n",
      "\tm9:  0.8723958333333333\n",
      "Predicted AUC score: 0.8775496883668008\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.3916666666666667)\n",
      "\tm0:  0.875425790754258\n",
      "\tm1:  0.915702479338843\n",
      "\tm2:  0.8767506413761198\n",
      "\tm3:  0.8936619423888958\n",
      "\tm4:  0.8842778553964373\n",
      "\tm5:  0.86034325983178\n",
      "\tm6:  0.8844503428445034\n",
      "\tm7:  0.8616940184736795\n",
      "\tm8:  0.8888316440257391\n",
      "\tm9:  0.8897824653922215\n",
      "Predicted AUC score: 0.8830920439822478\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.4208333333333334)\n",
      "\tm0:  0.8752619253050659\n",
      "\tm1:  0.8678554906001598\n",
      "\tm2:  0.916408237913486\n",
      "\tm3:  0.8833671828721334\n",
      "\tm4:  0.8911543835137967\n",
      "\tm5:  0.8869520607754104\n",
      "\tm6:  0.8496251874062969\n",
      "\tm7:  0.8859067108997163\n",
      "\tm8:  0.8545374642935618\n",
      "\tm9:  0.8977591036414566\n",
      "Predicted AUC score: 0.8808827747221084\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.45000000000000007)\n",
      "\tm0:  0.8817049207742798\n",
      "\tm1:  0.8800498753117209\n",
      "\tm2:  0.8552845528455285\n",
      "\tm3:  0.8567634922580382\n",
      "\tm4:  0.9027139374075701\n",
      "\tm5:  0.9039460784313725\n",
      "\tm6:  0.8826059850374064\n",
      "\tm7:  0.8451787198669991\n",
      "\tm8:  0.8403298350824588\n",
      "\tm9:  0.8611534230346112\n",
      "Predicted AUC score: 0.8709730820049986\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.47916666666666674)\n",
      "\tm0:  0.882814640829908\n",
      "\tm1:  0.9219987228607918\n",
      "\tm2:  0.8755073337351819\n",
      "\tm3:  0.8943273416957627\n",
      "\tm4:  0.8793263941778793\n",
      "\tm5:  0.8574430435744305\n",
      "\tm6:  0.8949969861362267\n",
      "\tm7:  0.8886138613861385\n",
      "\tm8:  0.8578877005347594\n",
      "\tm9:  0.8900922453554032\n",
      "Predicted AUC score: 0.8843008270286482\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.5083333333333334)\n",
      "\tm0:  0.8907763769077637\n",
      "\tm1:  0.8488354207866404\n",
      "\tm2:  0.8879379232030954\n",
      "\tm3:  0.9068539804171988\n",
      "\tm4:  0.8943873179091688\n",
      "\tm5:  0.8766973656029129\n",
      "\tm6:  0.8889365526821097\n",
      "\tm7:  0.9045261669024045\n",
      "\tm8:  0.8663673562173221\n",
      "\tm9:  0.8542707542267877\n",
      "Predicted AUC score: 0.8819589214855406\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.5375000000000001)\n",
      "\tm0:  0.8863873907772063\n",
      "\tm1:  0.8780992565802692\n",
      "\tm2:  0.8944529068291445\n",
      "\tm3:  0.9075771971496437\n",
      "\tm4:  0.888878246062154\n",
      "\tm5:  0.8582514016413424\n",
      "\tm6:  0.8766537849511253\n",
      "\tm7:  0.8588019559902199\n",
      "\tm8:  0.8752873563218391\n",
      "\tm9:  0.9089491986090571\n",
      "Predicted AUC score: 0.8833338694912001\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.5666666666666668)\n",
      "\tm0:  0.8653531887077665\n",
      "\tm1:  0.8773665393678394\n",
      "\tm2:  0.8857404820118756\n",
      "\tm3:  0.8630574595921132\n",
      "\tm4:  0.8486486486486486\n",
      "\tm5:  0.8481344205584384\n",
      "\tm6:  0.8717540367175403\n",
      "\tm7:  0.8721415119720204\n",
      "\tm8:  0.877007924609124\n",
      "\tm9:  0.9095279181560457\n",
      "Predicted AUC score: 0.8718732130341411\n",
      "Best Previous Score: 0.8881663199935789\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.5958333333333334)\n",
      "\tm0:  0.9104246183206106\n",
      "\tm1:  0.9005881357366506\n",
      "\tm2:  0.9015645371577574\n",
      "\tm3:  0.9044715447154472\n",
      "\tm4:  0.8599857853589197\n",
      "\tm5:  0.8870796083439761\n",
      "\tm6:  0.9017138538219552\n",
      "\tm7:  0.8713920817369093\n",
      "\tm8:  0.8653887342043265\n",
      "\tm9:  0.8907227594052166\n",
      "Predicted AUC score: 0.8893331658801769\n",
      "Best Previous Score: 0.8881663199935789\n",
      "!!!!!!!!!!!!!!!Found new best parameters!!!!!!!!\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.625)\n",
      "\tm0:  0.8882743828069143\n",
      "\tm1:  0.8796744484900407\n",
      "\tm2:  0.8810209584507905\n",
      "\tm3:  0.8908120770432066\n",
      "\tm4:  0.8878124308781242\n",
      "\tm5:  0.8665629209829516\n",
      "\tm6:  0.8965912436388106\n",
      "\tm7:  0.9036445973738333\n",
      "\tm8:  0.865826538176427\n",
      "\tm9:  0.902200488997555\n",
      "Predicted AUC score: 0.8862420086838654\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.6541666666666667)\n",
      "\tm0:  0.8668573174991268\n",
      "\tm1:  0.8892355371900826\n",
      "\tm2:  0.8917991700562883\n",
      "\tm3:  0.8491272882077481\n",
      "\tm4:  0.874599358974359\n",
      "\tm5:  0.8919628099173554\n",
      "\tm6:  0.864609310058188\n",
      "\tm7:  0.8808707793856309\n",
      "\tm8:  0.8793187347931873\n",
      "\tm9:  0.8748484848484849\n",
      "Predicted AUC score: 0.8763228790930452\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.6833333333333333)\n",
      "\tm0:  0.9075555555555556\n",
      "\tm1:  0.8653708187606493\n",
      "\tm2:  0.9143798762442831\n",
      "\tm3:  0.9066758706689232\n",
      "\tm4:  0.8764962593516208\n",
      "\tm5:  0.8736973367774117\n",
      "\tm6:  0.8806706902753908\n",
      "\tm7:  0.8507936507936507\n",
      "\tm8:  0.8608668477089528\n",
      "\tm9:  0.883589276418532\n",
      "Predicted AUC score: 0.8820096182554968\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.7125)\n",
      "\tm0:  0.8834167472767801\n",
      "\tm1:  0.8800553426990207\n",
      "\tm2:  0.8639130612411652\n",
      "\tm3:  0.8795019157088122\n",
      "\tm4:  0.9145268233875828\n",
      "\tm5:  0.8945324845365479\n",
      "\tm6:  0.8905163753265019\n",
      "\tm7:  0.9026587563172929\n",
      "\tm8:  0.8804669094024417\n",
      "\tm9:  0.8794816877275647\n",
      "Predicted AUC score: 0.886907010362371\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.7416666666666667)\n",
      "\tm0:  0.8761953118388762\n",
      "\tm1:  0.850369998745767\n",
      "\tm2:  0.8535334184759472\n",
      "\tm3:  0.8878798463150541\n",
      "\tm4:  0.8914747474747474\n",
      "\tm5:  0.8713679501651407\n",
      "\tm6:  0.8892161520190024\n",
      "\tm7:  0.8879631612765047\n",
      "\tm8:  0.8377249357326477\n",
      "\tm9:  0.8571685519005555\n",
      "Predicted AUC score: 0.8702894073944243\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.7708333333333334)\n",
      "\tm0:  0.8427070707070707\n",
      "\tm1:  0.8982419985700467\n",
      "\tm2:  0.8932064268250087\n",
      "\tm3:  0.8884297520661157\n",
      "\tm4:  0.8781193490054249\n",
      "\tm5:  0.8879693090219405\n",
      "\tm6:  0.8748613336620239\n",
      "\tm7:  0.8690541279387644\n",
      "\tm8:  0.8772378516624041\n",
      "\tm9:  0.9047824479230864\n",
      "Predicted AUC score: 0.8814609667381885\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.04526315789473684) (Depth = 5) (Gamma = 0.8)\n",
      "\tm0:  0.87255548231158\n",
      "\tm1:  0.8658146300914382\n",
      "\tm2:  0.9032951577255375\n",
      "\tm3:  0.8807151979565773\n",
      "\tm4:  0.897528131341081\n",
      "\tm5:  0.8673779774439608\n",
      "\tm6:  0.8463641334062328\n",
      "\tm7:  0.8606031875028218\n",
      "\tm8:  0.890930552823136\n",
      "\tm9:  0.8926224670470194\n",
      "Predicted AUC score: 0.8777806917649384\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.1)\n",
      "\tm0:  0.8812091704671515\n",
      "\tm1:  0.8760119940029985\n",
      "\tm2:  0.8759442823454174\n",
      "\tm3:  0.8757838992892647\n",
      "\tm4:  0.8832840104026544\n",
      "\tm5:  0.8611590356115904\n",
      "\tm6:  0.8797935103244838\n",
      "\tm7:  0.9024004631691459\n",
      "\tm8:  0.8718827930174563\n",
      "\tm9:  0.8580034057045551\n",
      "Predicted AUC score: 0.8765472564334719\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.12916666666666668)\n",
      "\tm0:  0.8848927630753795\n",
      "\tm1:  0.8878865979381442\n",
      "\tm2:  0.8666116611661165\n",
      "\tm3:  0.8508155474579213\n",
      "\tm4:  0.893188310261481\n",
      "\tm5:  0.8832904420064112\n",
      "\tm6:  0.8767755026747831\n",
      "\tm7:  0.8711779047923578\n",
      "\tm8:  0.8714201086734485\n",
      "\tm9:  0.8554039794995478\n",
      "Predicted AUC score: 0.8741462817545591\n",
      "Best Previous Score: 0.8893331658801769\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.15833333333333335)\n",
      "\tm0:  0.8907353986370666\n",
      "\tm1:  0.8755427841634738\n",
      "\tm2:  0.8964809640237513\n",
      "\tm3:  0.8957268406420948\n",
      "\tm4:  0.8931921487603306\n",
      "\tm5:  0.8803232323232324\n",
      "\tm6:  0.8960501819412712\n",
      "\tm7:  0.8797577490852503\n",
      "\tm8:  0.8920944512167592\n",
      "\tm9:  0.8963748437432648\n",
      "Predicted AUC score: 0.8896278594536495\n",
      "Best Previous Score: 0.8893331658801769\n",
      "!!!!!!!!!!!!!!!Found new best parameters!!!!!!!!\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.1875)\n",
      "\tm0:  0.8878611145950916\n",
      "\tm1:  0.8676687489154954\n",
      "\tm2:  0.8867712546472198\n",
      "\tm3:  0.893226294071986\n",
      "\tm4:  0.9036094207274586\n",
      "\tm5:  0.8717712572285287\n",
      "\tm6:  0.9003557296454694\n",
      "\tm7:  0.8873643619406332\n",
      "\tm8:  0.8963213604025682\n",
      "\tm9:  0.8597459004970502\n",
      "Predicted AUC score: 0.8854695442671501\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.21666666666666667)\n",
      "\tm0:  0.8615289256198347\n",
      "\tm1:  0.8399972329828445\n",
      "\tm2:  0.8578995226187769\n",
      "\tm3:  0.8645091481408618\n",
      "\tm4:  0.9206794889793626\n",
      "\tm5:  0.8576415495955725\n",
      "\tm6:  0.859713983911595\n",
      "\tm7:  0.8794423182066703\n",
      "\tm8:  0.888207747977863\n",
      "\tm9:  0.8741812336749046\n",
      "Predicted AUC score: 0.8703801151708286\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.24583333333333335)\n",
      "\tm0:  0.8905890714494753\n",
      "\tm1:  0.8756545025780407\n",
      "\tm2:  0.8948613160782533\n",
      "\tm3:  0.8715549657155497\n",
      "\tm4:  0.8514260177134965\n",
      "\tm5:  0.8664377996262289\n",
      "\tm6:  0.9046148609219997\n",
      "\tm7:  0.9025413223140496\n",
      "\tm8:  0.8850654099293085\n",
      "\tm9:  0.8686214775323686\n",
      "Predicted AUC score: 0.8811366743858772\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.275)\n",
      "\tm0:  0.8667302798982188\n",
      "\tm1:  0.8910788837618105\n",
      "\tm2:  0.8666630970229171\n",
      "\tm3:  0.8999115239991152\n",
      "\tm4:  0.8584875810789432\n",
      "\tm5:  0.8395297977036632\n",
      "\tm6:  0.8474776500638571\n",
      "\tm7:  0.8737405409925164\n",
      "\tm8:  0.8977566867989647\n",
      "\tm9:  0.8759039570975866\n",
      "Predicted AUC score: 0.8717279998417593\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.3041666666666667)\n",
      "\tm0:  0.8766809049201075\n",
      "\tm1:  0.8809776598097766\n",
      "\tm2:  0.8694970525523642\n",
      "\tm3:  0.8950724036155691\n",
      "\tm4:  0.9064686704834606\n",
      "\tm5:  0.8841315287176817\n",
      "\tm6:  0.9080127342839206\n",
      "\tm7:  0.8718316409580652\n",
      "\tm8:  0.9001652892561984\n",
      "\tm9:  0.9006810688877321\n",
      "Predicted AUC score: 0.8893518953484877\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.33333333333333337)\n",
      "\tm0:  0.87061860142287\n",
      "\tm1:  0.900789519347562\n",
      "\tm2:  0.8521049753963914\n",
      "\tm3:  0.8804688161123805\n",
      "\tm4:  0.8762020858729513\n",
      "\tm5:  0.9034098658786088\n",
      "\tm6:  0.8811308631398587\n",
      "\tm7:  0.8859630139681292\n",
      "\tm8:  0.8810344827586207\n",
      "\tm9:  0.8663838383838384\n",
      "Predicted AUC score: 0.879810606228121\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.36250000000000004)\n",
      "\tm0:  0.8709030100334448\n",
      "\tm1:  0.9038320617267986\n",
      "\tm2:  0.8730738398503607\n",
      "\tm3:  0.8829751440467679\n",
      "\tm4:  0.8761991361673108\n",
      "\tm5:  0.8762587797241262\n",
      "\tm6:  0.8984504132231406\n",
      "\tm7:  0.8600350488839696\n",
      "\tm8:  0.8819420188613343\n",
      "\tm9:  0.8828310393925013\n",
      "Predicted AUC score: 0.8806500491909756\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.3916666666666667)\n",
      "\tm0:  0.8808671439936356\n",
      "\tm1:  0.9058242362697809\n",
      "\tm2:  0.8833289953149401\n",
      "\tm3:  0.8721138074609917\n",
      "\tm4:  0.8958872591314352\n",
      "\tm5:  0.8872243691748123\n",
      "\tm6:  0.87416500774165\n",
      "\tm7:  0.8702000851426139\n",
      "\tm8:  0.8996161965073883\n",
      "\tm9:  0.8773420921937785\n",
      "Predicted AUC score: 0.8846569192931026\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.4208333333333334)\n",
      "\tm0:  0.8811639498304531\n",
      "\tm1:  0.8835437349348368\n",
      "\tm2:  0.8431885908897403\n",
      "\tm3:  0.9088658606793323\n",
      "\tm4:  0.8793505774402783\n",
      "\tm5:  0.883283102270444\n",
      "\tm6:  0.8735332464146024\n",
      "\tm7:  0.8783873649210306\n",
      "\tm8:  0.904484148515619\n",
      "\tm9:  0.8762396694214876\n",
      "Predicted AUC score: 0.8812040245317825\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.45000000000000007)\n",
      "\tm0:  0.8725160567265831\n",
      "\tm1:  0.8628741092636579\n",
      "\tm2:  0.8786420566908373\n",
      "\tm3:  0.8834810513447434\n",
      "\tm4:  0.8718161683277961\n",
      "\tm5:  0.8975688165561583\n",
      "\tm6:  0.9004069393874492\n",
      "\tm7:  0.8956060035954679\n",
      "\tm8:  0.8746981381942821\n",
      "\tm9:  0.8697374472176931\n",
      "Predicted AUC score: 0.8807346787304668\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.47916666666666674)\n",
      "\tm0:  0.9058912448420968\n",
      "\tm1:  0.8867390378884632\n",
      "\tm2:  0.864811864199044\n",
      "\tm3:  0.8785328345802161\n",
      "\tm4:  0.8672706589745673\n",
      "\tm5:  0.8869121140142519\n",
      "\tm6:  0.8617691154422789\n",
      "\tm7:  0.8931197692370195\n",
      "\tm8:  0.8659748727735369\n",
      "\tm9:  0.8310329573103297\n",
      "Predicted AUC score: 0.8742054469261804\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.5083333333333334)\n",
      "\tm0:  0.8609904090820121\n",
      "\tm1:  0.8721945137157108\n",
      "\tm2:  0.8595874933234726\n",
      "\tm3:  0.8648784408278078\n",
      "\tm4:  0.8889027431421447\n",
      "\tm5:  0.8635408230166994\n",
      "\tm6:  0.8667183930341824\n",
      "\tm7:  0.8763308763308764\n",
      "\tm8:  0.8450170785613824\n",
      "\tm9:  0.8853535353535353\n",
      "Predicted AUC score: 0.8683514306387826\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.5375000000000001)\n",
      "\tm0:  0.8940453770962246\n",
      "\tm1:  0.9059873270399585\n",
      "\tm2:  0.8944846407717695\n",
      "\tm3:  0.8960234680573663\n",
      "\tm4:  0.8574632637277648\n",
      "\tm5:  0.8716765546033839\n",
      "\tm6:  0.8946669522381667\n",
      "\tm7:  0.8690736342042755\n",
      "\tm8:  0.875941440297876\n",
      "\tm9:  0.9095218745767303\n",
      "Predicted AUC score: 0.8868884532613516\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.5666666666666668)\n",
      "\tm0:  0.8410370187764493\n",
      "\tm1:  0.8934329065908014\n",
      "\tm2:  0.900792460912401\n",
      "\tm3:  0.8757065669160431\n",
      "\tm4:  0.8846380544882991\n",
      "\tm5:  0.8933316408563934\n",
      "\tm6:  0.8612122510173486\n",
      "\tm7:  0.8655352480417754\n",
      "\tm8:  0.8693467336683417\n",
      "\tm9:  0.8657376686573768\n",
      "Predicted AUC score: 0.8750770549925229\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.5958333333333334)\n",
      "\tm0:  0.8932212700505382\n",
      "\tm1:  0.8681204212454213\n",
      "\tm2:  0.8822258120852252\n",
      "\tm3:  0.8927030691482803\n",
      "\tm4:  0.9026916695773664\n",
      "\tm5:  0.8699793918492661\n",
      "\tm6:  0.88595178719867\n",
      "\tm7:  0.8550867423431141\n",
      "\tm8:  0.8750889890840058\n",
      "\tm9:  0.8869055518690554\n",
      "Predicted AUC score: 0.8811974704450943\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.625)\n",
      "\tm0:  0.8565490227427155\n",
      "\tm1:  0.8792121212121212\n",
      "\tm2:  0.8740909651177123\n",
      "\tm3:  0.8897781750223451\n",
      "\tm4:  0.8655918767257504\n",
      "\tm5:  0.8614072093110852\n",
      "\tm6:  0.8756151519255948\n",
      "\tm7:  0.9080987595419847\n",
      "\tm8:  0.8972341075794621\n",
      "\tm9:  0.8941820914412275\n",
      "Predicted AUC score: 0.880175948062\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.6541666666666667)\n",
      "\tm0:  0.8892624922062885\n",
      "\tm1:  0.8794452347083925\n",
      "\tm2:  0.8953636563392661\n",
      "\tm3:  0.8736990154711674\n",
      "\tm4:  0.8750051068349879\n",
      "\tm5:  0.8823385218776811\n",
      "\tm6:  0.8662153736528012\n",
      "\tm7:  0.877985441668306\n",
      "\tm8:  0.8832396525293817\n",
      "\tm9:  0.8906027527289985\n",
      "Predicted AUC score: 0.8813157248017272\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.6833333333333333)\n",
      "\tm0:  0.8882743362831858\n",
      "\tm1:  0.8830074434031393\n",
      "\tm2:  0.8721065563170826\n",
      "\tm3:  0.8640151979409242\n",
      "\tm4:  0.8731313613231552\n",
      "\tm5:  0.9235742919953446\n",
      "\tm6:  0.8840443717715262\n",
      "\tm7:  0.8550279682045675\n",
      "\tm8:  0.853480402655815\n",
      "\tm9:  0.8820574643359453\n",
      "Predicted AUC score: 0.8778719394230684\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.7125)\n",
      "\tm0:  0.8906451761667589\n",
      "\tm1:  0.9116644069189368\n",
      "\tm2:  0.8892049302451578\n",
      "\tm3:  0.8713294406363714\n",
      "\tm4:  0.8771604938271605\n",
      "\tm5:  0.8998285881516787\n",
      "\tm6:  0.8715892926419242\n",
      "\tm7:  0.9093563370935634\n",
      "\tm8:  0.8623844186504033\n",
      "\tm9:  0.8661250740458661\n",
      "Predicted AUC score: 0.8849288158377823\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.7416666666666667)\n",
      "\tm0:  0.876908728093007\n",
      "\tm1:  0.8848481001946349\n",
      "\tm2:  0.8705271946564885\n",
      "\tm3:  0.8689160640286017\n",
      "\tm4:  0.8763975155279503\n",
      "\tm5:  0.8782967032967034\n",
      "\tm6:  0.901814620888125\n",
      "\tm7:  0.8819776714513556\n",
      "\tm8:  0.8849519375835166\n",
      "\tm9:  0.8834788029925186\n",
      "Predicted AUC score: 0.8808117338712901\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.7708333333333334)\n",
      "\tm0:  0.8735382760699216\n",
      "\tm1:  0.8893784589186887\n",
      "\tm2:  0.8741058042407367\n",
      "\tm3:  0.89119082756272\n",
      "\tm4:  0.8795115391289259\n",
      "\tm5:  0.8595630756050546\n",
      "\tm6:  0.8722084367245657\n",
      "\tm7:  0.8499920483460559\n",
      "\tm8:  0.8694343434343433\n",
      "\tm9:  0.8805983016509333\n",
      "Predicted AUC score: 0.8739521111681945\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045526315789473686) (Depth = 5) (Gamma = 0.8)\n",
      "\tm0:  0.8731634182908545\n",
      "\tm1:  0.8716434417164344\n",
      "\tm2:  0.8731632534999421\n",
      "\tm3:  0.8700663639538946\n",
      "\tm4:  0.8843572833506885\n",
      "\tm5:  0.8664382094666953\n",
      "\tm6:  0.8767245895913377\n",
      "\tm7:  0.8727476065052886\n",
      "\tm8:  0.8785939049096944\n",
      "\tm9:  0.8897777777777778\n",
      "Predicted AUC score: 0.8756675849062606\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045789473684210526) (Depth = 5) (Gamma = 0.1)\n",
      "\tm0:  0.8711515151515152\n",
      "\tm1:  0.8714075859731063\n",
      "\tm2:  0.8720747622207475\n",
      "\tm3:  0.8815867242555127\n",
      "\tm4:  0.8726118575126339\n",
      "\tm5:  0.9078925619834711\n",
      "\tm6:  0.8640378884631758\n",
      "\tm7:  0.8919754384489212\n",
      "\tm8:  0.8849115680798849\n",
      "\tm9:  0.8632282440887299\n",
      "Predicted AUC score: 0.8780878146177699\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045789473684210526) (Depth = 5) (Gamma = 0.12916666666666668)\n",
      "\tm0:  0.8766735537190083\n",
      "\tm1:  0.8818989898989901\n",
      "\tm2:  0.8526442307692308\n",
      "\tm3:  0.886759787527051\n",
      "\tm4:  0.8542509294439679\n",
      "\tm5:  0.8540540540540541\n",
      "\tm6:  0.8417588425789629\n",
      "\tm7:  0.8943600696092391\n",
      "\tm8:  0.9016054182867177\n",
      "\tm9:  0.8663115612993364\n",
      "Predicted AUC score: 0.8710317437186557\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045789473684210526) (Depth = 5) (Gamma = 0.15833333333333335)\n",
      "\tm0:  0.8952541057804215\n",
      "\tm1:  0.8751391539440203\n",
      "\tm2:  0.8955958655063938\n",
      "\tm3:  0.8813414440203562\n",
      "\tm4:  0.8882879893828799\n",
      "\tm5:  0.8658925016589251\n",
      "\tm6:  0.8549368173056329\n",
      "\tm7:  0.8816763736511806\n",
      "\tm8:  0.9004018240101134\n",
      "\tm9:  0.8740797156638741\n",
      "Predicted AUC score: 0.8812605790923798\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045789473684210526) (Depth = 5) (Gamma = 0.1875)\n",
      "\tm0:  0.8632895390311074\n",
      "\tm1:  0.8765581562191731\n",
      "\tm2:  0.8657865786578658\n",
      "\tm3:  0.9007149020091211\n",
      "\tm4:  0.9012233211868819\n",
      "\tm5:  0.8729940796136169\n",
      "\tm6:  0.8981045932484781\n",
      "\tm7:  0.896301652892562\n",
      "\tm8:  0.8964933833354887\n",
      "\tm9:  0.886744617247512\n",
      "Predicted AUC score: 0.8858210823441807\n",
      "Best Previous Score: 0.8896278594536495\n",
      "=================Scores================== (eta=0.045789473684210526) (Depth = 5) (Gamma = 0.21666666666666667)\n",
      "\tm0:  0.8483744070345944\n",
      "\tm1:  0.8617867697203909\n",
      "\tm2:  0.8798552932216298\n",
      "\tm3:  0.9010136727958509\n",
      "\tm4:  0.8991762105686156\n",
      "\tm5:  0.8711722929348829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier()\n\u001b[0;32m     19\u001b[0m model\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     21\u001b[0m score \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mroc_auc_score(y_test, model\u001b[39m.\u001b[39mpredict_proba(x_test)[:,\u001b[39m1\u001b[39m])\n\u001b[0;32m     22\u001b[0m tot_score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m score\n",
      "File \u001b[1;32mc:\\Users\\Jackson Paull\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jackson Paull\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1401\u001b[0m     params,\n\u001b[0;32m   1402\u001b[0m     train_dmatrix,\n\u001b[0;32m   1403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1404\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1405\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1406\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1407\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1408\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1409\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1410\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1411\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1412\u001b[0m )\n\u001b[0;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jackson Paull\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jackson Paull\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jackson Paull\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1777\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1779\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1780\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============== Hyperparameter Tuning ======================\n",
    "n_folds = 10\n",
    "\n",
    "for depth in np.arange(5, 7):\n",
    "    for eta in np.linspace(0.045, 0.05, 5):\n",
    "        for gamma in [0.1, 0.15, 0.2, 0.25, 0.3, 0.5, 0.7]:\n",
    "            print('=================Scores================== (eta=%s) (Depth = %s) (Gamma = %s)'%(eta, depth, gamma))\n",
    "            tot_score = 0\n",
    "            for i in range(n_folds):\n",
    "                x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) # Create split for dev stuff\n",
    "                params = {\n",
    "                    'objective':'binary:logistic',\n",
    "                    'eta': eta,\n",
    "                    'gamma':gamma,\n",
    "                    'max_depth':depth,\n",
    "                    'min_child_weight':1\n",
    "                }\n",
    "                model = xgb.XGBClassifier()\n",
    "                model.set_params(**params)\n",
    "                model.fit(x_train, y_train, verbose=False)\n",
    "                score = metrics.roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "                tot_score += score\n",
    "                print(f'\\tm{i}: ', score)\n",
    "            print(f'Predicted AUC score: {tot_score/n_folds}\\nBest Previous Score: {best_score}')\n",
    "            if best_score < tot_score/n_folds:\n",
    "                print('!!!!!!!!!!!!!!!Found new best parameters!!!!!!!!')\n",
    "                best_score = tot_score/n_folds\n",
    "                best_params = params\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.set_params(**best_params)\n",
    "model.fit(x, y)\n",
    "xg_preds = pd.DataFrame(model.predict_proba(test_df)[:,1], index=test_df.index, columns=['Y'])\n",
    "xg_preds.to_csv('./preds/xgb_tuned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'eta': 0.04842105263157895,\n",
       " 'gamma': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_score)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = params = {\n",
    "            'eta': 0.02,\n",
    "            'max_depth':4,\n",
    "            'n_estimators':1000\n",
    "        }\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Scores==================\n",
      "\tm0:  0.9306317539484621\n",
      "\tm1:  0.9052008863246791\n",
      "\tm2:  0.9108016067062522\n",
      "\tm3:  0.9176688063703583\n",
      "\tm4:  0.9020912938082912\n",
      "\tm5:  0.9058070989589866\n",
      "\tm6:  0.9037531476078181\n",
      "\tm7:  0.9089694486505745\n",
      "\tm8:  0.9040442741592167\n",
      "\tm9:  0.8552892561983472\n",
      "Predicted AUC score: 0.9044257572732987\n",
      "Best Score: 0\n",
      "!!!!!!!!!!!!!!!Found new best parameters!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "# ============== Hyperparameter Tuning ======================\n",
    "n_folds = 10\n",
    "print('=================Scores==================')\n",
    "tot_score = 0\n",
    "for i in range(n_folds):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) # Create split for dev stuff\n",
    "    params = {\n",
    "            'eta': 0.01,\n",
    "            'max_depth':5,\n",
    "            'n_estimators':1200\n",
    "        }\n",
    "    model = cb.CatBoostClassifier()\n",
    "    model.set_params(**params)\n",
    "    model.fit(x_train, y_train, verbose=False)\n",
    "    score = metrics.roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "    tot_score += score\n",
    "    print(f'\\tm{i}: ', score)\n",
    "print(f'Predicted AUC score: {tot_score/n_folds}\\nBest Previous Score: {best_score}')\n",
    "if best_score < tot_score/n_folds:\n",
    "    print('!!!!!!!!!!!!!!!Found new best parameters!!!!!!!!')\n",
    "    best_score = tot_score/n_folds\n",
    "    best_params = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb.CatBoostClassifier()\n",
    "model.set_params(**best_params)\n",
    "model.fit(x, y, verbose=False)\n",
    "cb_preds = pd.DataFrame(model.predict_proba(test_df)[:,1], index=test_df.index, columns=['Y'])\n",
    "cb_preds.to_csv('./preds/cb_tuned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/raw/train_final.csv', index_col = 0)\n",
    "x = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "test_df = pd.read_csv('./data/raw/test_final.csv', index_col=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42) # Create split for dev stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== CNN Using Torch ==================\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        # Probably want to include parameters here for defining the structure of the neural net\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def train(self, train_df):\n",
    "        pass\n",
    "\n",
    "    def predict(self, df):\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, df):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "- Stacked model of each best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Ensembling =================\n",
    "\n",
    "# Stacking\n",
    "# Create dataframe of predictions from xgboost, catboost, and neural net\n",
    "# Train logistic regression, neural net, xgboost, and catboost on \n",
    "n_folds = 10\n",
    "tot_score = 0\n",
    "for i in range(n_folds):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) # Create split for dev stuff\n",
    "    #Train best_params catboost\n",
    "    #Train best_params xgboost\n",
    "    ens_df = xg_preds.join(cb_preds, lsuffix='xg', rsuffix='cat')\n",
    "\n",
    "    #Train catboost on stacked df\n",
    "\n",
    "    #Test ensembled model on test data produce AUC score\n",
    "\n",
    "tot_score /= n_folds\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34b045790512ac9b0c81146f785aa12ac81151c219e716f613de13210c8d269f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
